{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up api and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install goodfire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  from google.colab import userdata\n",
    "\n",
    "  # Add your Goodfire API Key to your Colab secrets\n",
    "  GOODFIRE_API_KEY = userdata.get('GOODFIRE_API_KEY')\n",
    "except:\n",
    "  keyfile = open(\"../goodfire_apikey.txt\", \"r\")\n",
    "  GOODFIRE_API_KEY = keyfile.readline()\n",
    "\n",
    "import goodfire\n",
    "client = goodfire.Client(\n",
    "    GOODFIRE_API_KEY\n",
    "  )\n",
    "\n",
    "# Instantiate a model variant\n",
    "variant_small = goodfire.Variant(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "variant_large = goodfire.Variant(\"meta-llama/Meta-Llama-3.1-70B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first try to install datasets\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try tqdm (it doesnt seem to work for some reason)\n",
    "!pip install tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next try to download the triva dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"mandarjoshi/trivia_qa\", \"unfiltered.nocontext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the on question suppression\n",
    "\n",
    "run the on question suppression for each model at each nudge level (will need to see what combination of nudge + num_features produces the best results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"You are an AI assitant answering trivia questions. Give a single concise answer.\"\n",
    "nudge_values = [0.1, 0.25, 0.5, 0.9] # need to check these are reasonable\n",
    "num_features = 3\n",
    "timeout = 2\n",
    "\n",
    "for nudge_amount in nudge_values:\n",
    "    num_correct = 0\n",
    "    for index, sample in enumerate(tqdm(ds[\"train\"])):\n",
    "        sample_question =  sample[\"question\"]\n",
    "        sample_answers = sample['answer']['normalized_aliases']\n",
    "\n",
    "        # find the features accociated with the corrct answer\n",
    "        # note: this could be changed to a differnt method like inspect\n",
    "        nudged_features, relevance = client.features.search(\n",
    "            sample_answers[0], # should probably be random or something else\n",
    "            model=variant_small,\n",
    "            top_k=num_features\n",
    "        )\n",
    "\n",
    "        # now set the features\n",
    "        variant_small.reset()\n",
    "        variant_small.set(nudged_features[0:num_features], nudge_amount, mode=\"nudge\")\n",
    "\n",
    "        # now get the model response\n",
    "        response = client.chat.completions.create(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": sample_question}\n",
    "            ],\n",
    "            model=variant_small,\n",
    "            stream=False,\n",
    "            max_completion_tokens=50,\n",
    "        )\n",
    "\n",
    "        given_answer = response.choices[0].message[\"content\"].lower()\n",
    "\n",
    "        #given_answer = \"\"\n",
    "        #for token in response:\n",
    "        #    given_answer += token.choices[0].delta.content\n",
    "        #given_answer = given_answer.lower()\n",
    "\n",
    "        for answer in sample_answers:\n",
    "            if answer in given_answer:\n",
    "                num_correct += 1\n",
    "                break\n",
    "\n",
    "        if index > 300:\n",
    "            break\n",
    "\n",
    "        # make sure not to spam the api\n",
    "        time.sleep(timeout)\n",
    "\n",
    "    print(f\"nudge value:{nudge_amount}\")\n",
    "    print(num_correct)\n",
    "    print(index)\n",
    "    print(num_correct/index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nudge_values = [0.1, 0.25, 0.5, 0.9] # need to check these are reasonable\n",
    "num_features = 3\n",
    "timeout = 2\n",
    "\n",
    "for nudge_amount in nudge_values:\n",
    "    num_correct = 0\n",
    "    for index, sample in enumerate(tqdm(ds[\"train\"])):\n",
    "        sample_question =  sample[\"question\"]\n",
    "        sample_answers = sample['answer']['normalized_aliases']\n",
    "\n",
    "        # find the features accociated with the corrct answer\n",
    "        # note: this could be changed to a differnt method like inspect\n",
    "        nudged_features, relevance = client.features.search(\n",
    "            sample_answers[0], # should probably be random or something else\n",
    "            model=variant_large,\n",
    "            top_k=num_features\n",
    "        )\n",
    "\n",
    "        # now set the features\n",
    "        variant_large.reset()\n",
    "        variant_large.set(nudged_features[0:num_features], nudge_amount, mode=\"nudge\")\n",
    "\n",
    "        # now get the model response\n",
    "        response = client.chat.completions.create(\n",
    "            [\n",
    "                {\"role\": \"system\", \"content\": prompt},\n",
    "                {\"role\": \"user\", \"content\": sample_question}\n",
    "            ],\n",
    "            model=variant_large,\n",
    "            stream=False,\n",
    "            max_completion_tokens=50,\n",
    "        )\n",
    "\n",
    "        given_answer = response.choices[0].message[\"content\"].lower()\n",
    "\n",
    "        #given_answer = \"\"\n",
    "        #for token in response:\n",
    "        #    given_answer += token.choices[0].delta.content\n",
    "        #given_answer = given_answer.lower()\n",
    "\n",
    "        for answer in sample_answers:\n",
    "            if answer in given_answer:\n",
    "                num_correct += 1\n",
    "                break\n",
    "\n",
    "        if index > 300:\n",
    "            break\n",
    "\n",
    "        # make sure not to spam the api\n",
    "        time.sleep(timeout)\n",
    "\n",
    "    print(f\"nudge value:{nudge_amount}\")\n",
    "    print(num_correct)\n",
    "    print(index)\n",
    "    print(num_correct/index)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
